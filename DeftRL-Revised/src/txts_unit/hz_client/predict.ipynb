{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/md.raihansobhan/Desktop/BUET/4-2 Sessionals/CSE 472 | ML/online_class/ml/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9        |\n",
      "|    ep_rew_mean     | -5.07    |\n",
      "| time/              |          |\n",
      "|    fps             | 2210     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 512      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -4.94       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2215        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011521477 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | -0.0619     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.774       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 4.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -4.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2211        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010372347 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.737       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -4.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2246        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017912539 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -3.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2259        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012394462 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.688       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -3.65       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2239        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012812814 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    value_loss           | 0.501       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -3.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2252        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023261655 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0481     |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9         |\n",
      "|    ep_rew_mean          | -2.85     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 2299      |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0184409 |\n",
      "|    clip_fraction        | 0.164     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.79     |\n",
      "|    explained_variance   | 0.586     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 0.193     |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.0332   |\n",
      "|    value_loss           | 0.435     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -2.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2318        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018439764 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -2.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2332        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016293146 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0696      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0333     |\n",
      "|    value_loss           | 0.296       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -2.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2360        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014007303 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0495      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -2.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2376        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011463427 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -2.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2378        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009885509 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -1.79       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2392        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009866957 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -1.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2401        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011414919 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0251      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -1.67       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2412        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013850611 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.019      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    value_loss           | 0.0875      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -1.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2424        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010706078 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.845      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00208    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.0822      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -1.52       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2431        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009697652 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.0937      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -1.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2441        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006535963 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.729      |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.00562     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.0682      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9           |\n",
      "|    ep_rew_mean          | -1.33       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2446        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007719331 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.646      |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.0454      |\n",
      "-----------------------------------------\n",
      "Predicted PRIMARY_TO_SECONDARY mapping: {'h1': 'h4', 'h2': 'h1', 'h3': 'h6', 'h5': 'h4', 'h7': 'h4'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "class NodeEnvironment(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(NodeEnvironment, self).__init__()\n",
    "        self.data = data\n",
    "        self.hosts = data['Host'].values\n",
    "\n",
    "        # State includes features for all hosts\n",
    "        self.state = data.iloc[:, 1:].values  # Exclude 'Host' column\n",
    "\n",
    "        # Action space: Choose a secondary host for each primary host\n",
    "        self.action_space = spaces.Discrete(len(self.hosts))\n",
    "\n",
    "        # Observation space: Host features (normalized)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=1, shape=(self.state.shape[1],), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Current primary host index\n",
    "        self.current_primary_idx = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_primary_idx = 0\n",
    "        self._reset_host_states()\n",
    "        return self.state[self.current_primary_idx], {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if action < 0 or action >= len(self.hosts):\n",
    "            raise ValueError(f\"Invalid action: {action}\")\n",
    "\n",
    "        reward = self._calculate_reward(self.current_primary_idx, action)\n",
    "\n",
    "        # Update secondary host's state dynamically\n",
    "        self._update_host_state(action)\n",
    "\n",
    "        # Move to next primary host\n",
    "        self.current_primary_idx += 1\n",
    "        done = self.current_primary_idx >= len(self.hosts)\n",
    "        truncated = False  # This can be updated based on specific use cases\n",
    "\n",
    "        if not done:\n",
    "            next_state = self.state[self.current_primary_idx]\n",
    "        else:\n",
    "            next_state = np.zeros(self.state.shape[1])  # Return a zero vector when done\n",
    "\n",
    "        return next_state, reward, done, truncated, {}\n",
    "\n",
    "    def _calculate_reward(self, primary_idx, secondary_idx):\n",
    "        primary_features = self.state[primary_idx]\n",
    "        secondary_features = self.state[secondary_idx]\n",
    "\n",
    "        # Example reward function: prioritize low latency and high health\n",
    "        latency = primary_features[secondary_idx % len(primary_features)]\n",
    "        health = secondary_features[-1]\n",
    "\n",
    "        if np.isnan(latency) or np.isnan(health):\n",
    "            return 0\n",
    "\n",
    "        reward = health - latency\n",
    "        return reward\n",
    "\n",
    "    def _update_host_state(self, host_idx):\n",
    "        \"\"\"Dynamically update the state of the selected secondary host.\"\"\"\n",
    "        # Decrease health significantly\n",
    "        self.state[host_idx, -1] *= 0.7  # Reduce health by 30%\n",
    "        # Increase latency or other metrics significantly\n",
    "        self.state[host_idx, :-1] += 0.3  # Increase latency or other metrics\n",
    "\n",
    "    def _reset_host_states(self):\n",
    "        \"\"\"Reset the dynamic state of hosts.\"\"\"\n",
    "        self.state = self.data.iloc[:, 1:].values.copy()\n",
    "\n",
    "# Load the CSV data into a pandas DataFrame\n",
    "data = pd.read_csv(\"node_features_with_pairwise_metrics.csv\")\n",
    "\n",
    "# Normalize feature columns\n",
    "feature_cols = [col for col in data.columns if col.startswith(\"Latency\") or col.startswith(\"HopCount\") or col not in ['Host']]\n",
    "data[feature_cols] = data[feature_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "data.fillna(0, inplace=True)  # Replace NaN values with 0\n",
    "\n",
    "# Create the DRL environment\n",
    "env_train = NodeEnvironment(data)\n",
    "\n",
    "# Define a DRL agent (PPO example)\n",
    "class DRLAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def get_model(self, algo, model_kwargs):\n",
    "        if algo == \"ppo\":\n",
    "            return PPO(\"MlpPolicy\", self.env, verbose=1, **model_kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported algorithm\")\n",
    "\n",
    "# Initialize the agent and the PPO model\n",
    "agent = DRLAgent(env=env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 512,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\", model_kwargs=PPO_PARAMS)\n",
    "\n",
    "# Training the model\n",
    "model_ppo.learn(total_timesteps=10000)\n",
    "\n",
    "# Modify PRIMARY_TO_SECONDARY dynamically\n",
    "def predict_backup_mapping(model, env, primary_hosts):\n",
    "    mapping = {}\n",
    "    for primary in primary_hosts:\n",
    "        primary_idx = env.hosts.tolist().index(primary)\n",
    "        state = env.state[primary_idx]\n",
    "        action, _ = model.predict(state, deterministic=True)\n",
    "\n",
    "        # Exclude invalid secondary options\n",
    "        valid_secondary_hosts = [i for i in range(len(env.hosts)) if env.hosts[i] not in ['stamper', 'client', primary]]\n",
    "        if action not in valid_secondary_hosts:  # If selected secondary is invalid, choose the best available\n",
    "            valid_secondary_hosts = sorted(valid_secondary_hosts, key=lambda i: env.state[i, -1], reverse=True)  # Sort based on health or any other metric\n",
    "            if valid_secondary_hosts:\n",
    "                action = valid_secondary_hosts[0]\n",
    "        \n",
    "        secondary = env.hosts[action]\n",
    "        mapping[primary] = secondary\n",
    "        env._update_host_state(action)  # Update state after assigning backup\n",
    "\n",
    "    return mapping\n",
    "\n",
    "primary_hosts = ['h1', 'h2', 'h3', 'h5', 'h7']\n",
    "mapping = predict_backup_mapping(model_ppo, env_train, primary_hosts)\n",
    "print(\"Predicted PRIMARY_TO_SECONDARY mapping:\", mapping)\n",
    "\n",
    "import json\n",
    "\n",
    "def save_mapping_to_json(mapping, file_path=\"primary_to_secondary.json\"):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(mapping, file, indent=4)\n",
    "\n",
    "# Save the mapping\n",
    "save_mapping_to_json(mapping, file_path=\"primary_to_secondary.json\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
